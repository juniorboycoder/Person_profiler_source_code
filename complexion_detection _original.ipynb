{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING THE TRAINED COMPLEXION MODEL FOR DETECTION ON WEBCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import cvlib as cv\n",
    "                    \n",
    "# load trained complexion model\n",
    "model = load_model('complexion4.model')\n",
    "\n",
    "\n",
    "#load gender caffe model\n",
    "genderProto=\"gender_deploy.prototxt\"\n",
    "genderModel=\"gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "genderList=['Male','Female']\n",
    "\n",
    "\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)\n",
    "\n",
    "\n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "    \n",
    "classes = [\"black\", \"white\",\"yellow\"]\n",
    "\n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    "\n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "\n",
    "    # apply face detection\n",
    "    face, confidence = cv.detect_face(frame)\n",
    "\n",
    "\n",
    "    # loop through detected faces\n",
    "    for idx, f in enumerate(face):\n",
    "\n",
    "        # get corner points of face rectangle        \n",
    "        (startX, startY) = f[0], f[1]\n",
    "        (endX, endY) = f[2], f[3]\n",
    "\n",
    "        # draw rectangle over face\n",
    "        cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "\n",
    "        # crop the detected face region\n",
    "        face_crop = np.copy(frame[startY:endY,startX:endX])\n",
    "\n",
    "        if (face_crop.shape[0]) < 10 or (face_crop.shape[1]) < 10:\n",
    "            continue\n",
    "\n",
    "        # preprocessing for gender detection model\n",
    "        face_crop = cv2.resize(face_crop, (224,224))\n",
    "        face_crop2 = cv2.resize(face_crop, (227,227))\n",
    "        face_crop = face_crop.astype(\"float\") / 255.0\n",
    "        face_crop = img_to_array(face_crop)\n",
    "        face_crop = np.expand_dims(face_crop, axis=0)\n",
    "\n",
    "        # apply gender detection on face\n",
    "        conf = model.predict(face_crop)[0] # model.predict return a 2D matrix, ex: [[9.9993384e-01 7.4850512e-05]]\n",
    "\n",
    "        # get label with max accuracy\n",
    "        idx = np.argmax(conf)\n",
    "        label = classes[idx]\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label, conf[idx] * 100)\n",
    "\n",
    "        Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        Y2 = startY - 25 if startY - 15 > 10 else startY + 25\n",
    "        #gender\n",
    "        blob=cv2.dnn.blobFromImage(face_crop2, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds=genderNet.forward()\n",
    "        gender=genderList[genderPreds[0].argmax()]\n",
    "        #print(f'Gender: {gender}')\n",
    "\n",
    "        \n",
    "\n",
    "        #cv2.imshow(\"Detecting age and gender\", resultImg)\n",
    "\n",
    "        # write label and confidence above face rectangle\n",
    "        cv2.putText(frame, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "      \n",
    "        cv2.putText(frame, f'{gender}', (startX, Y2), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "    # display output\n",
    "    cv2.imshow(\"complexion detection\", frame)\n",
    "\n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
